param_groups:
  backbone: extractor.convnet
  add_on_layers: extractor.add_on
  prototypes: [classifier.prototypes, classifier.proto_slot_map]
  last_layer: classifier.last_layer

optimizers:
  warmup_optimizer:
    type: Adam
    groups:
      add_on_layers:
        lr: 0.0015
        weight_decay: 0.001
      prototypes:
        lr: 0.0015
  joint_optimizer:
    type: Adam
    groups:
      backbone:
        lr: 0.001
        weight_decay_rate: 0.0
        momentum: 0.9
      add_on_layers:
        lr: 0.001
        weight_decay_rate: 0.0
        momentum: 0.9
      prototypes:
        lr: 0.001
        weight_decay_rate: 0.0
        momentum: 0.9
    scheduler:
      type: StepLR
      params:
        step_size: 10
        gamma: 0.1
  last_layer_optimizer:
    type: Adam
    groups:
      last_layer:
        lr: 0.0001

num_epochs: 30

periods:
  warmup:
    num_epochs: 10
    freeze: [ backbone, last_layer ]
    optimizers: warmup_optimizer
  main_training:
    freeze: last_layer
    optimizers: joint_optimizer
    patience: 5

auxiliary_info:
  loss_coefficients:
    clustering: 0.8
    separability: -0.08
    regularization: 0.0001

epilogue:
  num_fine_tuning_epochs: 2