param_groups:
  backbone: extractor.convnet
  addons_and_prototypes: [extractor.add_on, classifier.prototypes]
  last_layer: classifier.last_layer

optimizers:
  # Optimizer used during the first epochs
  warmup_optimizer:
    type: Adam
    groups:
      addons_and_prototypes:
        lr: 0.003
        weight_decay_rate: 0.001

  # Main optimizer
  joint_optimizer:
    type: Adam
    groups:
      backbone:
        lr: 0.0001
        weight_decay_rate: 0.001
      addons_and_prototypes:
        lr: 0.003
        weight_decay_rate: 0.001
    scheduler:
      type: StepLR
      params:
        step_size: 5
        gamma: 0.1

  # Optimizer used during the first epochs
  last_layer_optimizer:
    type: Adam
    groups:
      last_layer:
        lr: 0.0001

num_epochs: 5

periods:
  warmup:
    epoch_range: [ 0, 2 ] # First and last epoch (included)
    freeze: [ backbone, last_layer ]
    optimizers: warmup_optimizer
  main_training:
    epoch_range: [ 3, 4 ]
    freeze: last_layer
    optimizers: joint_optimizer
  fine_tuning:
    epoch_range: [ 5, 5 ]
    freeze: [ backbone, addons_and_prototypes ]
    optimizers: last_layer_optimizer

# After training
# epilogue:
#   pruning_threshold: 0.01
