diff --git a/find_nearest.py b/find_nearest.py
index 3ef615e..b3b91f5 100644
--- a/find_nearest.py
+++ b/find_nearest.py
@@ -10,8 +10,8 @@ import time
 
 import cv2
 
-from receptive_field import compute_rf_prototype
-from helpers import makedir, find_high_activation_crop
+from .receptive_field import compute_rf_prototype
+from .helpers import makedir, find_high_activation_crop
 
 def imsave_with_bbox(fname, img_rgb, bbox_height_start, bbox_height_end,
                      bbox_width_start, bbox_width_end, color=(0, 255, 255)):
@@ -80,7 +80,7 @@ def find_k_nearest_patches_to_prototypes(dataloader, # pytorch dataloader (must
         heaps.append([])
 
     for idx, (search_batch_input, search_y) in enumerate(dataloader):
-        print('batch {}'.format(idx))
+        #print('batch {}'.format(idx))
         if preprocess_input_function is not None:
             # print('preprocessing input for pushing ...')
             # search_batch = copy.deepcopy(search_batch_input)
diff --git a/img_aug.py b/img_aug.py
index ca05b19..e6a2972 100644
--- a/img_aug.py
+++ b/img_aug.py
@@ -7,11 +7,10 @@ def makedir(path):
     if not os.path.exists(path):
         os.makedirs(path)
 
-datasets_root_dir = './datasets/cub200_cropped/'
-dir = datasets_root_dir + 'train_cropped/'
-target_dir = datasets_root_dir + 'train_cropped_augmented/'
 
-makedir(target_dir)
+dir = "data/CUB_200_2011/dataset/train_crop/"
+target_dir = "../../train_crop_augmented/"
+os.makedirs("data/CUB_200_2011/dataset/train_crop_augmented", exist_ok=True)
 folders = [os.path.join(dir, folder) for folder in next(os.walk(dir))[1]]
 target_folders = [os.path.join(target_dir, folder) for folder in next(os.walk(dir))[1]]
 
diff --git a/model.py b/model.py
index b8870ab..c4c7b0b 100644
--- a/model.py
+++ b/model.py
@@ -3,12 +3,12 @@ import torch.nn as nn
 import torch.utils.model_zoo as model_zoo
 import torch.nn.functional as F
 
-from resnet_features import resnet18_features, resnet34_features, resnet50_features, resnet101_features, resnet152_features
-from densenet_features import densenet121_features, densenet161_features, densenet169_features, densenet201_features
-from vgg_features import vgg11_features, vgg11_bn_features, vgg13_features, vgg13_bn_features, vgg16_features, vgg16_bn_features,\
+from .resnet_features import resnet18_features, resnet34_features, resnet50_features, resnet101_features, resnet152_features
+from .densenet_features import densenet121_features, densenet161_features, densenet169_features, densenet201_features
+from .vgg_features import vgg11_features, vgg11_bn_features, vgg13_features, vgg13_bn_features, vgg16_features, vgg16_bn_features,\
                          vgg19_features, vgg19_bn_features
 
-from receptive_field import compute_proto_layer_rf_info_v2
+from .receptive_field import compute_proto_layer_rf_info_v2
 
 base_architecture_to_features = {'resnet18': resnet18_features,
                                  'resnet34': resnet34_features,
diff --git a/prune.py b/prune.py
index b57430f..5d60aca 100644
--- a/prune.py
+++ b/prune.py
@@ -4,8 +4,8 @@ from collections import Counter
 import numpy as np
 import torch
 
-from helpers import makedir
-import find_nearest
+from .helpers import makedir
+from . import find_nearest
 
 def prune_prototypes(dataloader,
                      prototype_network_parallel,
diff --git a/push.py b/push.py
index f3eb146..4c36e47 100644
--- a/push.py
+++ b/push.py
@@ -6,8 +6,8 @@ import os
 import copy
 import time
 
-from receptive_field import compute_rf_prototype
-from helpers import makedir, find_high_activation_crop
+from .receptive_field import compute_rf_prototype
+from .helpers import makedir, find_high_activation_crop
 
 # push each prototype to the nearest patch in the training set
 def push_prototypes(dataloader, # pytorch dataloader (must be unnormalized in [0,1])
diff --git a/train_and_test.py b/train_and_test.py
index cb8c1c8..669223e 100644
--- a/train_and_test.py
+++ b/train_and_test.py
@@ -1,9 +1,10 @@
 import time
 import torch
 
-from helpers import list_of_distances, make_one_hot
+from .helpers import list_of_distances, make_one_hot
 
 def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l1_mask=True,
+                   max_batches: int | None = None,  # Enable early abort for retrocompatibility tests
                    coefs=None, log=print):
     '''
     model: the multi-gpu model
@@ -106,6 +107,10 @@ def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l
         del predicted
         del min_distances
 
+        if max_batches is not None and i == max_batches:
+           # Early abort when checking compatibility with CaBRNet
+           break
+
     end = time.time()
 
     log('\ttime: \t{0}'.format(end -  start))
@@ -124,13 +129,13 @@ def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l
     return n_correct / n_examples
 
 
-def train(model, dataloader, optimizer, class_specific=False, coefs=None, log=print):
+def train(model, dataloader, optimizer, class_specific=False, coefs=None, max_batches=None, log=print):
     assert(optimizer is not None)

     log('\ttrain')
     model.train()
     return _train_or_test(model=model, dataloader=dataloader, optimizer=optimizer,
-                          class_specific=class_specific, coefs=coefs, log=log)
+                          class_specific=class_specific, max_batches=max_batches, coefs=coefs, log=log)
 
 
 def test(model, dataloader, class_specific=False, log=print):
