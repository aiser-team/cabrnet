diff --git a/find_nearest.py b/find_nearest.py
index 3ef615e..b3b91f5 100644
--- a/find_nearest.py
+++ b/find_nearest.py
@@ -10,8 +10,8 @@ import time
 
 import cv2
 
-from receptive_field import compute_rf_prototype
-from helpers import makedir, find_high_activation_crop
+from .receptive_field import compute_rf_prototype
+from .helpers import makedir, find_high_activation_crop
 
 def imsave_with_bbox(fname, img_rgb, bbox_height_start, bbox_height_end,
                      bbox_width_start, bbox_width_end, color=(0, 255, 255)):
@@ -80,7 +80,7 @@ def find_k_nearest_patches_to_prototypes(dataloader, # pytorch dataloader (must
         heaps.append([])
 
     for idx, (search_batch_input, search_y) in enumerate(dataloader):
-        print('batch {}'.format(idx))
+        #print('batch {}'.format(idx))
         if preprocess_input_function is not None:
             # print('preprocessing input for pushing ...')
             # search_batch = copy.deepcopy(search_batch_input)
diff --git a/img_aug.py b/img_aug.py
index ca05b19..8783a8c 100644
--- a/img_aug.py
+++ b/img_aug.py
@@ -1,5 +1,6 @@
 import Augmentor
 import os
+import random
 def makedir(path):
     '''
     if path does not exist in the file system, create it
@@ -7,11 +8,11 @@ def makedir(path):
     if not os.path.exists(path):
         os.makedirs(path)
 
-datasets_root_dir = './datasets/cub200_cropped/'
-dir = datasets_root_dir + 'train_cropped/'
-target_dir = datasets_root_dir + 'train_cropped_augmented/'
-
-makedir(target_dir)
+# Set random seed for reproducibility
+random.seed(0)
+dir = "data/CUB_200_2011/dataset/train_crop/"
+target_dir = "../../train_crop_augmented/"
+os.makedirs("data/CUB_200_2011/dataset/train_crop_augmented", exist_ok=True)
 folders = [os.path.join(dir, folder) for folder in next(os.walk(dir))[1]]
 target_folders = [os.path.join(target_dir, folder) for folder in next(os.walk(dir))[1]]
 
@@ -20,24 +21,24 @@ for i in range(len(folders)):
     tfd = target_folders[i]
     # rotation
     p = Augmentor.Pipeline(source_directory=fd, output_directory=tfd)
-    p.rotate(probability=1, max_left_rotation=15, max_right_rotation=15)
+    p.rotate(probability=1, max_left_rotation=10, max_right_rotation=10) # Reduce angle to avoid errors in Augmentor
     p.flip_left_right(probability=0.5)
     for i in range(10):
-        p.process()
+        p.sample(0, multi_threaded=False) # Use single thread for reproducibility
     del p
     # skew
     p = Augmentor.Pipeline(source_directory=fd, output_directory=tfd)
     p.skew(probability=1, magnitude=0.2)  # max 45 degrees
     p.flip_left_right(probability=0.5)
     for i in range(10):
-        p.process()
+        p.sample(0, multi_threaded=False) # Use single thread for reproducibility
     del p
     # shear
     p = Augmentor.Pipeline(source_directory=fd, output_directory=tfd)
     p.shear(probability=1, max_shear_left=10, max_shear_right=10)
     p.flip_left_right(probability=0.5)
     for i in range(10):
-        p.process()
+        p.sample(0, multi_threaded=False) # Use single thread for reproducibility
     del p
     # random_distortion
     #p = Augmentor.Pipeline(source_directory=fd, output_directory=tfd)
diff --git a/model.py b/model.py
index b8870ab..dc24b37 100644
--- a/model.py
+++ b/model.py
@@ -3,12 +3,12 @@ import torch.nn as nn
 import torch.utils.model_zoo as model_zoo
 import torch.nn.functional as F
 
-from resnet_features import resnet18_features, resnet34_features, resnet50_features, resnet101_features, resnet152_features
-from densenet_features import densenet121_features, densenet161_features, densenet169_features, densenet201_features
-from vgg_features import vgg11_features, vgg11_bn_features, vgg13_features, vgg13_bn_features, vgg16_features, vgg16_bn_features,\
+from .resnet_features import resnet18_features, resnet34_features, resnet50_features, resnet101_features, resnet152_features
+from .densenet_features import densenet121_features, densenet161_features, densenet169_features, densenet201_features
+from .vgg_features import vgg11_features, vgg11_bn_features, vgg13_features, vgg13_bn_features, vgg16_features, vgg16_bn_features,\
                          vgg19_features, vgg19_bn_features
 
-from receptive_field import compute_proto_layer_rf_info_v2
+from .receptive_field import compute_proto_layer_rf_info_v2
 
 base_architecture_to_features = {'resnet18': resnet18_features,
                                  'resnet34': resnet34_features,
@@ -33,7 +33,7 @@ class PPNet(nn.Module):
     def __init__(self, features, img_size, prototype_shape,
                  proto_layer_rf_info, num_classes, init_weights=True,
                  prototype_activation_function='log',
-                 add_on_layers_type='bottleneck'):
+                 add_on_layers_type='bottleneck', seed=None):
 
         super(PPNet, self).__init__()
         self.img_size = img_size
@@ -75,6 +75,10 @@ class PPNet(nn.Module):
         else:
             raise Exception('other base base_architecture NOT implemented')
 
+        if seed is not None:
+            # For RNG synchronisation with CaBRNet
+            torch.manual_seed(seed)
+
         if add_on_layers_type == 'bottleneck':
             add_on_layers = []
             current_in_channels = first_add_on_layer_in_channels
@@ -288,7 +292,7 @@ class PPNet(nn.Module):
 def construct_PPNet(base_architecture, pretrained=True, img_size=224,
                     prototype_shape=(2000, 512, 1, 1), num_classes=200,
                     prototype_activation_function='log',
-                    add_on_layers_type='bottleneck'):
+                    add_on_layers_type='bottleneck', seed=None):
     features = base_architecture_to_features[base_architecture](pretrained=pretrained)
     layer_filter_sizes, layer_strides, layer_paddings = features.conv_info()
     proto_layer_rf_info = compute_proto_layer_rf_info_v2(img_size=img_size,
@@ -303,5 +307,5 @@ def construct_PPNet(base_architecture, pretrained=True, img_size=224,
                  num_classes=num_classes,
                  init_weights=True,
                  prototype_activation_function=prototype_activation_function,
-                 add_on_layers_type=add_on_layers_type)
+                 add_on_layers_type=add_on_layers_type, seed=seed)
 
diff --git a/prune.py b/prune.py
index b57430f..5d60aca 100644
--- a/prune.py
+++ b/prune.py
@@ -4,8 +4,8 @@ from collections import Counter
 import numpy as np
 import torch
 
-from helpers import makedir
-import find_nearest
+from .helpers import makedir
+from . import find_nearest
 
 def prune_prototypes(dataloader,
                      prototype_network_parallel,
diff --git a/push.py b/push.py
index f3eb146..4c36e47 100644
--- a/push.py
+++ b/push.py
@@ -6,8 +6,8 @@ import os
 import copy
 import time
 
-from receptive_field import compute_rf_prototype
-from helpers import makedir, find_high_activation_crop
+from .receptive_field import compute_rf_prototype
+from .helpers import makedir, find_high_activation_crop
 
 # push each prototype to the nearest patch in the training set
 def push_prototypes(dataloader, # pytorch dataloader (must be unnormalized in [0,1])
diff --git a/train_and_test.py b/train_and_test.py
index cb8c1c8..0e42254 100644
--- a/train_and_test.py
+++ b/train_and_test.py
@@ -1,7 +1,7 @@
 import time
 import torch
 
-from helpers import list_of_distances, make_one_hot
+from .helpers import list_of_distances, make_one_hot
 
 def _train_or_test(model, dataloader, optimizer=None, class_specific=True, use_l1_mask=True,
                    coefs=None, log=print):
